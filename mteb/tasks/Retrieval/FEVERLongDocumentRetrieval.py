import datasets
from ...abstasks.AbsTaskRetrieval import AbsTaskRetrieval


class FEVERLongDocumentRetrieval(AbsTaskRetrieval):

    _EVAL_SPLIT = 'test'

    @property
    def description(self):
        return {
            'name': 'FEVERLongDocumentRetrieval',
            'hf_hub_name': 'fever',
            'reference': 'https://nlp.cs.washington.edu/triviaqa/',
            "description": (
                "FEVER (Fact Extraction and VERification) consists of 18,544 claims generated by altering sentences"
                " extracted from Wikipedia and subsequently verified without knowledge of the sentence they were"
                " derived from. This task takes claims which have supporting evidence as queries."
                " Whole Wikipedia articles are retrieved as documents."
            ),
            "reference": "https://fever.ai/",
            "type": "Retrieval",
            "category": "s2p",
            "eval_splits": ["test"],
            "eval_langs": ["en"],
            "main_score": "ndcg_at_10",
        }

    def load_data(self, **kwargs):
        if self.data_loaded:
            return

        query_rows = datasets.load_dataset(self.description['hf_hub_name'], 'v1.0', split='paper_test')
        corpus_rows = datasets.load_dataset('wikipedia', '20220301.en', split='train')
        corpus_titles = [title.replace(' ', '_') for title in corpus_rows['title']]
        qrels_rows = [{'id': row['id'], 'evidence_wiki_url': row['evidence_wiki_url']} for row in query_rows if row['label'] == 'SUPPORTS' and row['evidence_wiki_url'] in corpus_titles]

        self.queries = {self._EVAL_SPLIT: {row['id']: row['claim'] for row in query_rows}}
        self.corpus = {self._EVAL_SPLIT: {row['title'].replace(' ', '_'): {'text': row['text']} for row in corpus_rows}}
        self.relevant_docs = {
            self._EVAL_SPLIT: {row['id']: {row['evidence_wiki_url']: 1} for row in qrels_rows}
        }

        self.data_loaded = True
